{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is convolutional neural Network\n",
    "- Convolutional Operation\n",
    "- Poolig Layer\n",
    "- Flattening\n",
    "- Full connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is convolutional neural Network (CNN)\n",
    "\n",
    "In deep learning, a convolutional neural network is a class of deep neural networks, most commonly applied to analyzing visual imagery(Images). CNNs use a variation of multilayer operations designed to require minimal preprocessing.\n",
    "\n",
    "Lets take example of some images:\n",
    "\n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv1.PNG)\n",
    "\n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv2.PNG)\n",
    "\n",
    "\n",
    "Even humans can diffreciate among images, so vast research is going on to make our Learning alogoritms to become stronger.\n",
    "\n",
    "This is the drawback of current neural networks model, But they are efficient enough in 99% of the cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Algoritm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images\n",
    "\n",
    "A visible impression obtained by a camera, telescope, microscope, or other device, or displayed on a computer or video screen.\n",
    "\n",
    "Resolution refers to the number of pixels in an image. Resolution is sometimes identified by the width and height of the image as well as the total number of pixels in the image\n",
    "\n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Image we will be dealing in Deep Learning\n",
    "\n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv5.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv6.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Convolution \n",
    "\n",
    "Convolution is a simple mathematical operation which is fundamental to many common image processing operators. \n",
    "\n",
    "In image processing, a kernel, convolution matrix, or mask is a small matrix used for Convolution Operation.\n",
    "\n",
    "In deep learning it is also known as feature detector which gives us feature map. In a single convolution layer we can have as many number of feature maps as we want.\n",
    "\n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv7.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv8.PNG)\n",
    "\n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv9.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in Convolutional nural network we use convolutional layer which consist of convolution operation with fearture detectors to obtain feature maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv10.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxpooling Operation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we perform maxpooling operation to our feature maps as below. \n",
    "\n",
    "It chooses the maximum value among the window or kernel by traversing the whole image or array of image. In the below image kernel size is 2X2\n",
    "\n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv11.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv12.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultant overview of Convolution and Maxpooling\n",
    "\n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv13.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Flattening is the process of converting all the resultant 2 dimensional arrays into a single long continuous linear vector.\n",
    " \n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv14.PNG)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv15.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole convolutional neural network till now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv16.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Connection\n",
    "\n",
    "After flattening we add simple neural network layers as we saw in house prediction dataset to our convolutional neural network \n",
    "\n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv17.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Convolution Neural Network\n",
    "\n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv18.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final layer you will get the probability of the image form the dataset in which you have trained your network.\n",
    "\n",
    "### Example \n",
    "![](https://raw.githubusercontent.com/Swati707/Machine-Learning-Lab-STC/master/Lab%20Day%203/conv19.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Handwritten Digit Recognition in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up environment and dependencies\n",
    "\n",
    "Run below commands in your terminal:\n",
    "\n",
    "- conda install -y -c anaconda \\\n",
    "  tensorflow-gpu h5py cudatoolkit=8\n",
    "  \n",
    "- pip install keras\n",
    "\n",
    "### Loading the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and spilitting the 'MNIST' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Here we are using dataset from the Keras package. You can use your own dataset.\n",
    "\n",
    "### Preprocessing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the image samples of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "  plt.subplot(3,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(x_train[i,:,:,0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Digit: {}\".format(y_train[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Class to Categorical Class conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Convolving the input feature vectors\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Max-pooling the convolved feature vector\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Applying dropout\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flattening the feature vector, i.e. the image into a 1-dimentional vector\n",
    "model.add(Flatten())\n",
    "\n",
    "# Adding a neural network fully connected layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train[:5000], y_train[:5000],\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test[:1000], y_test[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    img = x_test[i,:,:,0]\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(img, cmap='gray', interpolation='none')\n",
    "    plt.title(\"Digit: {}\".format(y_train[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    y_pred = model.predict(img)\n",
    "    print('Ground truth:', y_test)\n",
    "    print('Predicted value:', y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Resources:\n",
    "- https://www.coursera.org/specializations/deep-learning\n",
    "- https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "- https://towardsdatascience.com/tagged/deep-learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
